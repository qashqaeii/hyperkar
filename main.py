import streamlit as st
import json
import requests
from bs4 import BeautifulSoup
import pandas as pd
import io
import os
rows = []
def extract(category):

    if category == 'Ù…ÙˆØªÙˆØ±':
        keyword = 'engine'
    elif category == 'Ø³ÛŒØ³ØªÙ… Ø§Ù†ØªÙ‚Ø§Ù„ Ù‚Ø¯Ø±Øª':
        keyword = 'Transmission'
    elif category == 'Ø³ÛŒØ³ØªÙ… Ø§Ù„Ú©ØªØ±ÛŒÚ©ÛŒ Ø®ÙˆØ¯Ø±Ùˆ':
        keyword = 'Electronic-system'
    elif category == 'Ø³ÛŒØ³ØªÙ… Ù‡Ø§ÛŒ Ø±ÙØ§Ù‡ÛŒ Ùˆ Ø§ÛŒÙ…Ù†ÛŒ':
        keyword = 'Welfare-and-safety'
    elif category == 'Ø´Ø§Ø³ÛŒ ÙˆØ¨Ø¯Ù†Ù‡ Ø®ÙˆØ¯Ø±Ùˆ':
        keyword = 'Chassis-and-car-body'
    elif category == 'Ø³ÛŒØ³ØªÙ… ØµÙˆØªÛŒ Ùˆ ØªØµÙˆÛŒØ±ÛŒ':
        keyword = 'Audio-and-video-system'
    elif category == 'Ø³ÛŒØ³ØªÙ… ØªØ¹Ù„ÛŒÙ‚ØŒ ØªØ±Ù…Ø² Ùˆ Ø§ÛŒÙ…Ù†ÛŒ':
        keyword = 'Suspension-brakes-and-steering'
    elif category == 'Ù…Ø§ÛŒØ¹Ø§Øª Ùˆ Ø±ÙˆØ§Ù† Ú©Ø§ÙˆÙ‡Ø§':
        keyword = 'Fluids-and-lubricants'
    elif category == 'Ù…Ú©Ù…Ù„ Ù‡Ø§ ØŒ Ø§Ø³Ù¾Ø±ÛŒ Ù‡Ø§ Ùˆ ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡ Ù‡Ø§':
        keyword = 'Supplements-sprays-and-cleaners'
    elif category == 'Ù‚Ø·Ø¹Ø§Øª Ø¢Ù¾Ø´Ù†':
        keyword = 'Options'

    headers = {
        'authority': 'services.hypercariran.com',
        'accept': 'application/json, text/javascript, */*; q=0.01',
        'accept-language': 'en,fa;q=0.9',
        'content-type': 'application/json; charset=UTF-8',
        'customerid': 'yTxBQysP+dnf8UpthP9gJg==',
        'origin': 'https://www.hypercariran.com',
        'referer': 'https://www.hypercariran.com/',
        'sec-ch-ua': '"Chromium";v="116", "Not)A;Brand";v="24", "Google Chrome";v="116"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'empty',
        'sec-fetch-mode': 'cors',
        'sec-fetch-site': 'same-site',
        'token': 'VGwMlD90mfSTRL/JN5nEHkf/OTT/Cm5FSu91bxV3tefJYkkV/CaZ0IAJX0no1cgMze4KvdJl1vb0n/0TxL1TaJq5IYGzwIR0x5YNMRQBAy0anb+M5rHtGfUwRPP/64lqyneDhX7/Bu7db8xMoZbZPiYqQiWhXYc5tNL/l2TvGK9LiihKxIsmAGG9i6D0bO55xx2wDv1HiNmLKt8WmPH/uw==',
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
    }

    json_data = {
        'where_clause': f'https://www.hypercariran.com/search/{keyword}=undefined&group={keyword}',
        'sort': '',
        'pagenumber': '1',
        'pagesize': '30',
    }

    response = requests.post('https://services.hypercariran.com/OnlineShop.asmx/GET_All_Product', headers=headers,
                             json=json_data)
    data = response.json()
    l_cat = []
    for item in data['dt_ChildrenGroup']:
        cat_name = item['categoryName']
        l_cat.append(cat_name)
    st.markdown("------")
    st.text_area("Ù„ÛŒØ³Øª Ø²ÛŒØ± Ø¯Ø³ØªÙ‡ Ù‡Ø§", value=l_cat)
    st.markdown("------")

    pages = data['pageCount'][0]['pageCount']
    pages = int(pages)

    all_items = data['pageCount'][0]['rowCount']
    col1, col2 = st.columns([2, 2])
    st.write(f"Ù„Ø·ÙØ§ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯ ØªØ§ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆÙ†Ø¯ ØŒ Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ :  {pages} Ø«Ø§Ù†ÛŒÙ‡ ")

    col1.write(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØµÙØ­Ø§Øª : {pages}")
    col2.write(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª : {all_items}")
    st.markdown("------")

    n = 1
    pagess = 1
    for i in range(1, pages):

        headers = {
            'authority': 'services.hypercariran.com',
            'accept': 'application/json, text/javascript, */*; q=0.01',
            'accept-language': 'en,fa;q=0.9',
            'content-type': 'application/json; charset=UTF-8',
            'customerid': 'yTxBQysP+dnf8UpthP9gJg==',
            'origin': 'https://www.hypercariran.com',
            'referer': 'https://www.hypercariran.com/',
            'sec-ch-ua': '"Chromium";v="116", "Not)A;Brand";v="24", "Google Chrome";v="116"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-site',
            'token': 'VGwMlD90mfSTRL/JN5nEHkf/OTT/Cm5FSu91bxV3tefJYkkV/CaZ0IAJX0no1cgMze4KvdJl1vb0n/0TxL1TaJq5IYGzwIR0x5YNMRQBAy0anb+M5rHtGfUwRPP/64lqyneDhX7/Bu7db8xMoZbZPiYqQiWhXYc5tNL/l2TvGK9LiihKxIsmAGG9i6D0bO55xx2wDv1HiNmLKt8WmPH/uw==',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
        }

        json_data = {
            'where_clause': f'https://www.hypercariran.com/search/{keyword}=undefined&group={keyword}',
            'sort': '',
            'pagenumber': f'{i}',
            'pagesize': '30',
        }

        response = requests.post('https://services.hypercariran.com/OnlineShop.asmx/GET_All_Product', headers=headers,
                                 json=json_data)
        data = response.json()
        items = data['dt_Data']

        for item in items:
            title = item['name']
            price =item['minPrice']
            image = item['img']
            productCode = item['productCode']
            productCode = int(productCode)
            productlink = f"https://www.hypercariran.com/product/{productCode}"
            row = {
                "Ø´Ù…Ø§Ø±Ù‡": n,
                "Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„": title,
                "Ù‚ÛŒÙ…Øª": price,
                "Ù„ÛŒÙ†Ú© Ù…Ø­ØµÙˆÙ„": productlink,
                "Ù„ÛŒÙ†Ú© Ø¹Ú©Ø³": image,
                }
            n = n+1
            rows.append(row)
    return(rows)

def scrape_item(item):
    url = f"https://www.hypercariran.com/product/{item}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    detailsParts = soup.find('div', class_='detailsPart')
    detailsParts = detailsParts.text.replace("Ø´Ù†Ø§Ø³Ù‡ Ù…Ø­ØµÙˆÙ„", "").strip(":")
    return (detailsParts)


st.set_page_config(
    page_title="Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú¯Ø± Ø­Ø³Ù† Ù¾ÙˆØ±",
)
st.markdown("""
<style type="text/css">
body{
 direction:rtl;
}
</style>
""",unsafe_allow_html=True)
st.markdown("# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ø³Ø§ÛŒØª Ù‡Ø§ÛŒÙ¾Ø±Ú©Ø§Ø±  ")



option = st.selectbox(
    'ÛŒÚ© Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ',
    ('Ù…ÙˆØªÙˆØ±', 'Ø³ÛŒØ³ØªÙ… Ø§Ù†ØªÙ‚Ø§Ù„ Ù‚Ø¯Ø±Øª', 'Ø³ÛŒØ³ØªÙ… Ø§Ù„Ú©ØªØ±ÛŒÚ©ÛŒ Ø®ÙˆØ¯Ø±Ùˆ', 'Ø³ÛŒØ³ØªÙ… Ù‡Ø§ÛŒ Ø±ÙØ§Ù‡ÛŒ Ùˆ Ø§ÛŒÙ…Ù†ÛŒ', 'Ø³ÛŒØ³ØªÙ… ØªØ¹Ù„ÛŒÙ‚ØŒ ØªØ±Ù…Ø² Ùˆ Ø§ÛŒÙ…Ù†ÛŒ',
     'Ø´Ø§Ø³ÛŒ ÙˆØ¨Ø¯Ù†Ù‡ Ø®ÙˆØ¯Ø±Ùˆ', 'Ù…Ø§ÛŒØ¹Ø§Øª Ùˆ Ø±ÙˆØ§Ù† Ú©Ø§ÙˆÙ‡Ø§', 'Ù…Ú©Ù…Ù„ Ù‡Ø§ ØŒ Ø§Ø³Ù¾Ø±ÛŒ Ù‡Ø§ Ùˆ ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡ Ù‡Ø§', 'Ø³ÛŒØ³ØªÙ… ØµÙˆØªÛŒ Ùˆ ØªØµÙˆÛŒØ±ÛŒ',
     'Ù‚Ø·Ø¹Ø§Øª Ø¢Ù¾Ø´Ù†'))

if st.button("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"):
    scrap = extract(option)
    st.write("Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡: ğŸ“ ")
    st.markdown("""
            <style type="text/css">
        body{
         direction:ltr;
        }
        </style>
            """,unsafe_allow_html=True)

    st.dataframe(scrap, width=1500, height=500)
    df = pd.DataFrame(data=scrap)
    df.to_excel("hypercar_data.xlsx", index=False)
    with open("hypercar_data.xlsx", "rb") as file:
        data = file.read()
        st.download_button(
            label="Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ Excel",
            data=data,
            file_name="hypercar_data.xlsx",
            key="excel-download",
        )
    st.markdown("# ØªÙ‚Ø¯ÛŒÙ… Ø´Ù…Ø§ Ø¢Ù‚Ø§ÛŒ Ø­Ø³Ù† Ù¾ÙˆØ±")
    st.write("Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯ ... ")
    st.write("Ø³Ø§Ø²Ù†Ø¯Ù‡ Ø­Ø³ÛŒÙ† Ù‚Ø´Ù‚Ø§ÛŒÛŒ 09357930033")
    